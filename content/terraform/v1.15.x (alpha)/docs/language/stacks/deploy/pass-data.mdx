---
page_title: Pass data from one Stack to another
description: Learn how to link Stacks together to pass data from one Stack to another using `publish_output` blocks to export data and `upstream_input` blocks to consume that data.
# START AUTO GENERATED METADATA, DO NOT EDIT
created_at: 2025-11-19T19:11:19Z
last_modified: 2025-11-19T19:11:19Z
# END AUTO GENERATED METADATA
---

# Pass data from one Stack to another

If you have multiple Stacks that do not share a provisioning lifecycle, you can link Stacks together to export data from one Stack for another to consume. If the output value of a Stack changes after a run, HCP Terraform automatically triggers runs for any Stacks that depend on those outputs.

## Background

You may need to pass data between different Stacks in your project. For example, one Stack in your organization may manage shared services, such as networking infrastructure, and another Stack may manage application components. Using separate Stacks lets you manage the infrastructure independently, but you can still need to share data between your networking and application Stacks.

To output information from a Stack, declare a `publish_output` block in the deployment configuration of the Stack exporting data. We refer to the Stack that declares a `publish_output` block as the upstream Stack.

To consume the data exported by the upstream Stack, declare an `upstream_input` block in the deployment configuration of a different Stack in the same project. We refer to the Stack that declares an `upstream_input` block as the downstream Stack.

## Requirements and limitations

Downstream Stacks must reside in the same project as their upstream Stacks.

The following limitations apply to passing data between Stacks:
- Stacks can link to up to 20 other upstream Stacks. [Learn more about passing data between Stacks](/terraform/language/stacks/deploy/pass-data).
- Stacks can expose values to up to 25 downstream Stacks. [Learn more about passing data between Stacks](/terraform/language/stacks/deploy/pass-data).

## Expose outputs to another Stack

You can declare an `output` block in your component configuration to expose a value from your Stack to the HCP Terraform UI:

<CodeBlockConfig filename="components.tfcomponent.hcl">

```hcl
output "vpc_id" {
  description = "The VPC ID of the networking Stack"
  type        = string
  value       = component.vpc.vpc_id
}

component "vpc" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "~> 5.0"

  # ...
}
```

</CodeBlockConfig>

The `publish_output` block, in your deployment configuration, makes an `output` value available to other Stacks in the same project. You must declare a `publish_output` block in your deployment configuration for each value you want to expose from the current Stack.

The following example defines a `publish_output` block to expose the value of the `vpc_id` output in the `network` deployment as `vpc_id_network`:

<CodeBlockConfig filename="network.tfdeploy.hcl">

```hcl
publish_output "vpc_id_network" {
  description = "The networking Stack's VPC's ID."
  value       = deployment.network.vpc_id
}

deployment "network" {
  # ...
}
```

</CodeBlockConfig>

You can reference a value from a deployment's outputs using `deployment.<DEPLOYMENT_NAME>.<OUTPUT_NAME>` syntax. After applying your configuration, any Stack in the same project can now reference your network deployment's `vpc_id_network` output by declaring an `upstream_input` block.

Once you apply a component configuration version that includes your `publish_output` block, HCP Terraform publishes a snapshot of those values, enabling HCP Terraform to resolve them. You must apply your Stack’s deployment configuration before any downstream Stacks can reference your Stack's published outputs.

Learn more about the [`publish_output` block](/terraform/language/block/stack/tfdeploy/publish_output).

## Consume the output from an upstream Stack

Declare an `upstream_input` block in your Stack’s deployment configuration to read values from another Stack's `publish_output` block. Adding an `upstream_input` block creates a dependency on the upstream Stack.

For example, if you want to use the output `vpc_id_network` from an upstream Stack in the same project, declare an `upstream_input` block in your deployment configuration.

<CodeBlockConfig filename="application.tfdeploy.hcl">

```hcl
# Application Stack deployment configuration

upstream_input "network_stack" {
  type   = "stack"
  source = "app.terraform.io/hashicorp/Default Project/networking-stack"
}

deployment "application" {
  inputs = {
    vpc_id = upstream_input.network_stack.vpc_id_network
  }
}
```

</CodeBlockConfig>

After pushing your Stack's configuration into HCP Terraform, HCP Terraform searches for the most recently published snapshot of the upstream Stack your configuration references. If no snapshot exists, the downstream Stack's run fails.

If HCP Terraform finds a published snapshot for your referenced upstream Stack, then all of that Stack's outputs are available to this downstream Stack. Add `upstream_input` blocks for every upstream Stack you want to reference. Learn more about the [`upstream_input` block](/terraform/language/block/stack/tfdeploy/upstream_input).

## Trigger runs when output values change

If an upstream Stack's published output values change, HCP Terraform automatically triggers runs for any downstream Stacks that rely on those outputs.

In the following example, the `application` deployment depends on the upstream networking Stack.

<CodeBlockConfig filename="application.tfdeploy.hcl">

```hcl
# Application Stack deployment configuration

upstream_input "network_stack" {
  type   = "stack"
  source = "app.terraform.io/hashicorp/Default Project/networking-stack"
}

deployment "application" {
  inputs = {
    vpc_id = upstream_input.network_stack.vpc_id_network
  }
}
```

</CodeBlockConfig>

The application Stack depends on the networking Stack’s output, so if the `vpc_id_network` changes then HCP Terraform triggers a new run for the application Stack. This approach allows you to decouple Stacks that have separate life cycles and ensures that updates in an upstream Stack propagate to downstream Stacks.

## Remove upstream Stack dependencies

To stop depending on an upstream Stack’s outputs, do the following in your downstream Stack's deployment configuration:

1. Remove the upstream Stack's `upstream_input` block
1. Remove any references to the upstream Stack's outputs
1. Push your configuration changes to HCP Terraform and apply the new configuration
