## Scaling Beyond Two Nodes

Terraform Enterprise supports scaling up to five nodes as part of the Active/Active deployment. When scaling beyond two nodes, you should also carefully evaluate and scale external services, particularly the database server. Regardless of the number of nodes, you must drain and scale down to a single node before upgrading.

### PostgreSQL Server

The Terraform Enterprise PostgreSQL server will typically hit the CPU capacity before other resources, so we recommend closely monitoring the CPU in a two-node configuration before scaling up to three or more nodes. You may also need to manually modify the database maximum connection count to allow for the additional load. Defaults vary, so please refer to the documentation for the cloud hosting your installation.

- [AWS - RDS connection limits](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html#RDS_Limits.MaxConnections)
- [AWS - Aurora Scaling](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Managing.Performance.html)
- [Azure - Azure Database Limits](https://docs.microsoft.com/en-us/azure/postgresql/concepts-limits)
- [Google Cloud - Cloud SQL Quotes and Limits](https://cloud.google.com/sql/docs/quotas)
- [PostgreSQL 12 - Connection Documentation](https://www.postgresql.org/docs/12/runtime-config-connection.html)

### Redis Server

Some workloads may rarely cause spikes in the Redis server CPU or memory. We recommend monitoring the Redis server and scaling it up as necessary.

- [AWS - Monitoring ElastiCache for Redis with CloudWatch](https://aws.amazon.com/blogs/database/monitoring-best-practices-with-amazon-elasticache-for-redis-using-amazon-cloudwatch/)
- [Azure - Monitor Azure Cache for Redis](https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-how-to-monitor)
- [Google Cloud - Monitoring Redis Instances](https://cloud.google.com/memorystore/docs/redis/monitoring-instances)

### Network Infrastructure/API Limits

As you scale Terraform Enterprise beyond two nodes, you may be adding additional stress to your network and dramatically increasing the number of API calls made in your cloud account. Each cloud has its own default limits and processes by which those limits might be increased. Please refer to the documentation for the cloud hosting your installation.

- [AWS - EC2 instance network limits](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-network-bandwidth.html)
- [AWS - Request Throttling for the EC2 API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/throttling.html)
- [Azure - Virtual Machine Network Limits](https://docs.microsoft.com/en-us/azure/virtual-network/virtual-machine-network-throughput)
- [Azure - Resource Manager Throttling](https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/request-limits-and-throttling)
- [Google Cloud - Network Quotas and Limits](https://cloud.google.com/vpc/docs/quota)
- [Google Cloud - API rate limits](https://cloud.google.com/compute/docs/api-rate-limits)

Depending on your infrastructure and Terraform Enterprise configuration, you may need to configure your application gateway or load balancer for sticky sessions. Sticky session refers to the practice of using a load balancer or gateway device with a specific setting enabled that ensures traffic is routed back to the original system that initiated a request. For example, an Active/Active deployment on Azure with SAML authentication requires sticky sessions to ensure the authentication with the SAML server is successful. The terminology for this varies across clouds. Refer to the documentation for your infrastructure.

- [AWS - Sticky Sessions for your Application Load Balancer](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/sticky-sessions.html)
- [AWS - Configure sticky sessions for your Classic Load Balancer](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html)
- [Azure - Application Gateway Cookie-based affinity](https://docs.microsoft.com/en-us/azure/application-gateway/configuration-http-settings#cookie-based-affinity)
- [Azure - Load Balancer distribution modes: Session Persistence](https://docs.microsoft.com/en-us/azure/load-balancer/distribution-mode-concepts#session-persistence)
- [Google Cloud - Session affinity](https://cloud.google.com/load-balancing/docs/https#session_affinity)

### HCP Terraform agents - Alternative Solution

Instead of scaling Terraform Enterprise beyond two to five nodes, you can use [HCP Terraform agents](/terraform/enterprise/admin/agents-on-tfe). HCP Terraform agents can run in other regions, other clouds, and even private clouds. Agents poll Terraform Enterprise for work and then Terraform plans and applies will run on the target system that has the agent executable installed. This has a much smaller impact on the Terraform Enterprise servers than running Terraform locally.
