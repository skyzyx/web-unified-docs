### Amazon CloudWatch

Sending to Amazon CloudWatch is only supported when Terraform Enterprise is
located within AWS due to how Fluent Bit reads AWS credentials.

This example configuration forwards all logs to Amazon CloudWatch. Refer to the
[`cloudwatch_logs` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/cloudwatch)
for more information.

```ini
[OUTPUT]
    Name               cloudwatch_logs
    Match              *
    region             us-east-1
    log_group_name     example-log-group
    log_stream_name    example-log-stream
    auto_create_group  On
```

-> **Note:** In Terraform Enterprise installations using AWS external services,
Fluent Bit will have access to the same `AWS_ACCESS_KEY_ID` and
`AWS_SECRET_ACCESS_KEY` environment variables that are used for object storage.

### Amazon S3

Sending to Amazon S3 is only supported when Terraform Enterprise is located
within AWS due to how Fluent Bit reads AWS credentials.

This example configuration forwards all logs to Amazon S3. Refer to the
[`s3` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/s3)
for more information.

```ini
[OUTPUT]
    Name                          s3
    Match                         *
    bucket                        example-bucket
    region                        us-east-1
    total_file_size               250M
    s3_key_format                 /$TAG/%Y/%m/%d/%H/%M/%S/$UUID.gz
    s3_key_format_tag_delimiters  .-
```

-> **Note:** In Terraform Enterprise installations using AWS external services,
Fluent Bit will have access to the same `AWS_ACCESS_KEY_ID` and
`AWS_SECRET_ACCESS_KEY` environment variables that are used for object storage.

### Azure Blob Storage

This example configuration forwards all logs to Azure Blob Storage. Refer to the
[`azure_blob` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/azure_blob)
for more information.

```ini
[OUTPUT]
    name                   azure_blob
    match                  *
    account_name           example-account-name
    shared_key             example-access-key
    path                   logs
    container_name         example-container-name
    auto_create_container  on
    tls                    on
```

### Azure Log Analytics

This example configuration forwards all logs to Azure Log Analytics. Refer to
the [`azure` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/azure)
for more information.

```ini
[OUTPUT]
    name         azure
    match        *
    Customer_ID  example-log-analytics-workspace-id
    Shared_Key   example-access-key
```

### Datadog

This example configuration forwards all logs to Datadog. Refer to the
[`datadog` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/datadog)
for more information.

```ini
[OUTPUT]
    Name        datadog
    Match       *
    Host        http-intake.logs.datadoghq.com
    TLS         on
    compress    gzip
    apikey      example-api-key
    dd_service  terraform_enterprise
    dd_source   docker
    dd_tags     environment:development,owner:engineering
```

### Forward

This example configuration forwards all logs to a listening Fluent Bit or
Fluentd instance. Refer to the
[`forward` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/forward)
for more information.

```ini
[OUTPUT]
    Name   forward
    Match  *
    Host   fluent.example.com
    Port   24224
```

### Google Cloud Platform Cloud Logging

Sending to Google Cloud Platform Cloud Logging is only supported when Terraform
Enterprise is located within GCP due to how Fluent Bit reads GCP credentials.

This example configuration forwards all logs to Google Cloud Platform Cloud
Logging (formerly known as Stackdriver). Refer to the
[`stackdriver` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/stackdriver)
for more information.

```ini
[OUTPUT]
    Name       stackdriver
    Match      *
    location   us-east1
    namespace  terraform_enterprise
    node_id    example-hostname
    resource   generic_node
```

-> **Note:** In Terraform Enterprise installations using GCP external services,
Fluent Bit will have access to the `GOOGLE_SERVICE_CREDENTIALS` environment
variable that points to a file containing the same GCP Service Account JSON
credentials that are used for object storage.

### Splunk Enterprise HTTP Event Collector (HEC)

This example configuration forwards all logs to Splunk Enterprise via the HTTP
Event Collector (HEC) interface. Refer to the
[`splunk` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/splunk)
for more information.

```ini
[OUTPUT]
    Name          splunk
    Match         *
    Host          example-splunk-hec-endpoint
    Port          8088
    Splunk_Token  example-splunk-token
```

### Syslog

This example configuration forwards all logs to a Syslog-compatible endpoint.
Refer to the
[`syslog` Fluent Bit output plugin documentation](https://docs.fluentbit.io/manual/pipeline/outputs/syslog)
for more information.

```ini
[OUTPUT]
    Name                 syslog
    Match                *
    host                 example-syslog-host
    port                 514
    mode                 tcp
    syslog_message_key   log
    syslog_severity_key  PRIORITY
    syslog_hostname_key  _HOSTNAME
    syslog_appname_key   SYSLOG_IDENTIFIER
    syslog_procid_key    _PID
```

<Note title="Warning">
The `syslog_message_key` should not be changed from `log`. If that value is changed, the application will no longer forward logs.
</Note>